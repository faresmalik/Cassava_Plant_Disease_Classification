{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import LeafDataset\n",
    "from torchvision import transforms\n",
    "from train_validate import Train_Validate\n",
    "import timm \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the root dir for train_images\n",
    "train_images_dir = './/train_images'\n",
    "csv_path = './train.csv'\n",
    "\n",
    "#Define params \n",
    "batch_size = 64\n",
    "shuffle_train = True\n",
    "shuffle_test = False\n",
    "num_workers = 12\n",
    "num_classes = 5\n",
    "image_size = (224,224)\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(csv_path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(data_df.label.values, bins= 50)\n",
    "plt.title('Classes Distribution')\n",
    "_ = plt.xticks([* range(5)])\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Class Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Test/Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , test_df = train_test_split(data_df, test_size=0.1, stratify=data_df.label, random_state=random_state)\n",
    "train_df.reset_index(inplace = True, drop = True)\n",
    "test_df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (8,4), sharey = True, sharex= True)\n",
    "_ = ax[0].hist(train_df.label.values, bins= 50)\n",
    "_ = ax[0].set_xticks([* range(5)])\n",
    "_ = ax[0].set_ylabel('Class Count')\n",
    "ax[0].set_title('Training')\n",
    "_ = ax[1].hist(test_df.label.values, bins= 50)\n",
    "_ = ax[1].set_xticks([* range(5)])\n",
    "ax[1].set_title('Testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of images in each class in the training set. \n",
    "classes_counts_dict= pd.value_counts(train_df.label).to_dict()\n",
    "print(f'Classes Counts \\n {classes_counts_dict}')\n",
    "\n",
    "classes_counts_sorted = {i : classes_counts_dict[i] for i in range(num_classes)}\n",
    "print(f'Sorted Classes Counts \\n {classes_counts_sorted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class weights\n",
    "sum_samples = np.array(list(classes_counts_sorted.values())).sum()\n",
    "class_weights = 1./(np.array(list(classes_counts_sorted.values()))/sum_samples)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomResizedCrop(size = image_size, scale = (0.95,1.0)),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([  \n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = LeafDataset(\n",
    "    csv_file = './train.csv' , \n",
    "    root_dir = train_images_dir, \n",
    "    transform = train_transform, \n",
    "    mode= 'train', \n",
    "    random_state= random_state)\n",
    "\n",
    "test_dataset = LeafDataset(\n",
    "    csv_file = './train.csv' , \n",
    "    root_dir = train_images_dir, \n",
    "    transform = test_transform, \n",
    "    mode= 'test', \n",
    "    random_state= random_state)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset= train_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = shuffle_train, \n",
    "    num_workers= num_workers, \n",
    "    drop_last= True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset= test_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = shuffle_test, \n",
    "    num_workers= num_workers, \n",
    "    drop_last= True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show image\n",
    "plt.imshow(test_dataset[200][0].numpy().transpose(1,2,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('transformer-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37906e3799e3dad222cfed0447967870e65218c8bdbf06cfd0739074c03b6910"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
