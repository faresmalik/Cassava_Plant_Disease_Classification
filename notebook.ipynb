{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import LeafDataset\n",
    "from torchvision import transforms\n",
    "from train_validate import Train_Validate\n",
    "import timm \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the root dir for train_images\n",
    "train_images_dir = '/home/faris.almalik/Desktop/plants_diseas/train_images'\n",
    "csv_path = './train.csv'\n",
    "\n",
    "#Define params \n",
    "batch_size = 64\n",
    "shuffle_train = True\n",
    "shuffle_test = False\n",
    "num_workers = 12\n",
    "num_classes = 5\n",
    "image_size = (224,224)\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(csv_path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(data_df.label.values, bins= 50)\n",
    "plt.title('Classes Distribution')\n",
    "_ = plt.xticks([* range(5)])\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Class Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Test/Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , test_df = train_test_split(data_df, test_size=0.1, stratify=data_df.label, random_state=random_state)\n",
    "train_df.reset_index(inplace = True, drop = True)\n",
    "test_df.reset_index(inplace = True, drop = True)\n",
    "# train_df.to_csv('train_new.csv', index = False)\n",
    "# test_df.to_csv('test_new.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (8,4), sharey = True, sharex= True)\n",
    "_ = ax[0].hist(train_df.label.values, bins= 50)\n",
    "_ = ax[0].set_xticks([* range(5)])\n",
    "_ = ax[0].set_ylabel('Class Count')\n",
    "ax[0].set_title('Training')\n",
    "_ = ax[1].hist(test_df.label.values, bins= 50)\n",
    "_ = ax[1].set_xticks([* range(5)])\n",
    "ax[1].set_title('Testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of images in each class in the training set. \n",
    "classes_counts_dict= pd.value_counts(train_df.label).to_dict()\n",
    "print(f'Classes Counts \\n {classes_counts_dict}')\n",
    "\n",
    "classes_counts_sorted = {i : classes_counts_dict[i] for i in range(num_classes)}\n",
    "print(f'Sorted Classes Counts \\n {classes_counts_sorted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_samples = np.array(list(classes_counts_sorted.values())).sum()\n",
    "class_weights = 1./(np.array(list(classes_counts_sorted.values()))/sum_samples)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomResizedCrop(size = image_size, scale = (0.95,1.0)),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([  \n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = LeafDataset(\n",
    "    csv_file = './train.csv' , \n",
    "    root_dir = train_images_dir, \n",
    "    transform = train_transform, \n",
    "    mode= 'train', \n",
    "    random_state= random_state)\n",
    "\n",
    "test_dataset = LeafDataset(\n",
    "    csv_file = './train.csv' , \n",
    "    root_dir = train_images_dir, \n",
    "    transform = test_transform, \n",
    "    mode= 'test', \n",
    "    random_state= random_state)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset= train_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = shuffle_train, \n",
    "    num_workers= num_workers, \n",
    "    drop_last= True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset= test_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = shuffle_test, \n",
    "    num_workers= num_workers, \n",
    "    drop_last= True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_dataset[200][0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Criterion and Optim \n",
    "lr = 2e-5\n",
    "epochs = 1\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype = torch.float).cuda())\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# model = torchvision.models.resnet50(pretrained=True, progress=True)\n",
    "# model.fc = torch.nn.Linear(in_features= model.fc.in_features, out_features=num_classes)\n",
    "model = timm.create_model('vit_base_patch16_224_in21k', pretrained =True, num_classes = 5).cuda()\n",
    "optimizer = torch.optim.Adam(params= model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object = Train_Validate(\n",
    "    model = model, train_loader = train_dataloader,\n",
    "    test_loader= test_dataloader, epochs = epochs, optimizer = optimizer,\n",
    "    criterion = criterion, device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model \n",
    "train_acc, train_loss, f1_train = model_object.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, '--*', color = 'yellow', label = 'Train ACC', alpha = 0.7)\n",
    "plt.plot(train_loss, '--o', color = 'black', label = 'Train Loss')\n",
    "plt.plot(f1_train, '-x', color = 'green', label = 'Train F1_Score', alpha = 0.2)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xticks([i for i in range(1,epochs)])\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('transformer-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37906e3799e3dad222cfed0447967870e65218c8bdbf06cfd0739074c03b6910"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
